---
title: "Lab-08: Modeling Data 1"
author: "Ednita J Tavarez-Jimenez"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: journal
editor_options: 
  chunk_output_type: console
---
## Penguin Boot 1

```{r}
require(palmerpenguins)
require(here)
require(boot)
dat_pen = droplevels(subset(penguins, species != "Gentoo"))
{
  boxplot(
    flipper_length_mm ~ species, data = dat_pen,
    ylab = "Flipper length (mm)")
}
#Parametric Two-Sample Test
t.test(flipper_length_mm ~ species, data = dat_pen, alternative = "less")

#Bootstrap Two-Sample Test
#install.packages("simpleboot")
require(simpleboot)

#Use two.boot

dat_ad <- subset(dat_pen,species == "Adelie", select = "flipper_length_mm")
dat_chin <- subset(dat_pen, species == "Chinstrap", select = "flipper_length_mm")

pen_boot <- two.boot(na.omit(dat_ad$flipper_length_mm), na.omit(dat_chin$flipper_length_mm), FUN = mean , R= 10000)

mean(quantile(
  pen_boot$t,
  c(0.025, 0.975)))
median(quantile(
  pen_boot$t,
  c(0.025, 0.975)))
```

**Q1: Calculate the standard deviation of the differences in mean flipper length from your bootstrap simulation.**

The standard deviation of the differences in mean flipper length is 2.82
```{r}
sd(quantile(
  pen_boot$t,
  c(0.025, 0.975)))
```

**Q2: Include your histogram of bootstrapped differences in your lab report (you donâ€™t need to show the R-code but make sure your plot includes appropriate title, axes, etc.)**
```{r}
hist(pen_boot$t, main = "Histogram of 10000 bootstrap differences in mean penguin flipper length", xlab = "Difference in mean flipper length (mm) Adelie and Chinstrap Penguing", col = "pink")
```

**Q3: What was the 95% bootstrap CI you calculated using quantile()? Show the R-code you used to answer the question.**

The 95% bootstrap CI I calculated using quantile() was 7.85.
```{r}
quantile(
  pen_boot$t,
  c(0.025, 0.975))
```

**Q4:Do you think the resampled differences in means follow a skewed distribution? Your answer should make reference to the mean, median, and histogram of the differences in means.**

## Penguin ECDF

**Q5: Show the R-code you used to create pen_ecdf()**
```{r}
pen_ecdf <- ecdf(pen_boot$t)
```

**Q6: What is the probability, according to the empirical distribution function, of observing a mean difference of -4.5 or greater? Show the R code you used to perform the calculation.**

```{r}
#total area is always 1 so to look at the right you have to 1- left area
arealeft <- pen_ecdf(-4.5)
area_right <- 1 - arealeft
print(arealeft)
total = arealeft + area_right
```

**Q7: What is the probability, according to the empirical distribution function, of observing a mean difference of -8 or smaller? Show the R code you used to perform the calculation.**

```{r}
area_1 <- pen_ecdf(-8)
```

##Hypothesis

**Q8: State the null and alternative hypotheses of a two-sample, two-tailed test for the difference in mean flipper lengths between the two penguin species.**

The null hypothesis is that there will be no difference in the mean of the flipper lengths of the two species.
The alternative hypothesis is that there is a difference in the mean of the flipper length between two penguin species.

##Pines, Non-Parametric Test

**Q9: What was the p-value? Show the R-code you used to find out**

The p-value was 0.1005
```{r}
require(here)
dat_veg_1 <- read.csv(here("data", "vegdata.csv"))
dat_veg = droplevels(subset(dat_veg_1, treatment %in% c("control", "clipped")))

boxplot(pine ~ treatment, data = dat_veg,
    ylab = "Pine")
table(dat_veg$treatment)

wilcox.test(pine ~ treatment, data = dat_veg, alternative = "less")
```

## Pines, Bootstrap

**Q10: What were the endpoints of your bootstrap CI? Show the R-code you used to find out.**

The endpoints are 2.5% = 4.25 and 97.5% = 29.6
```{r}
dat_clip <- subset(dat_veg, treatment == "clipped")
dat_con <- subset(dat_veg, treatment == "control")

tree_boot <- two.boot(na.omit(dat_clip$pine), na.omit(dat_con$pine), FUN = mean , R= 10000)

boot.ci(tree_boot)
```

**Q11: What is the observed difference in mean tree counts and does it fall within the 95% bootstrap CI?**

The observed mean difference in tree counts is 16 which falls in the 95% bootstrap CI. 
```{r}
mean(quantile(tree_boot$t, c(0.025, 0.95)))
hist(tree_boot$t, main = "Ednita's sampling distribution", xlab = "Resampled differences in mean", col = "pink")
```

## Resampling Model Coefficients 

**Q12:Briefly describe the Simpson diversity index, and explain what it quantifies.**

The Simpson diversity index is measures diversity. It quantifies the number of species present and the abundance.

**Q13: Show the code you used to z-standardize the s.sidi column**
```{r}
dat_bird <- read.csv(here("data", "bird.sub.csv"))
dat_habitat <- read.csv(here("data", "hab.sub.csv"))
dat_all = merge(
  dat_bird, 
  dat_habitat,
  by = c("basin", "sub"))

head(dat_all[, c("b.sidi", "s.sidi")])

# Calculate the sample mean and sd:
b_sidi_mean = mean(dat_all$b.sidi, na.rm = TRUE)
b_sidi_sd   = sd(dat_all$b.sidi, na.rm = TRUE)

# Use the subset-by-name symbol ($) to create a 
# new column of z-standardized values.

dat_all$b.sidi.standardized = (dat_all$b.sidi - b_sidi_mean)/b_sidi_sd

mean(dat_all$b.sidi.standardized)
sd(dat_all$b.sidi.standardized)

```


```{r}
plot(
  b.sidi ~ s.sidi, data = dat_all,
  main = "Simpson's diversity indices",
  xlab = "Vegetation cover diversity",
  ylab = "Bird diversity")

fit_1 = lm(b.sidi ~ s.sidi, data = dat_all)
coef(fit_1)
slope_observed = coef(fit_1)[2]

plot(
  b.sidi ~ s.sidi, data = dat_all,
  main = "Simpson's diversity indices",
  xlab = "Vegetation cover diversity",
  ylab = "Bird diversity")
abline(fit_1)

dat_1 = 
  subset(
    dat_all,
    select = c(b.sidi, s.sidi))
```

**Q14: Show the code for your completed Monte Carlo simulation loop.**

```{r}
set.seed(123)
index_1 = sample(nrow(dat_1), replace = TRUE)
index_2 = sample(nrow(dat_1), replace = TRUE)

dat_resampled_i = 
  data.frame(
    b.sidi = dat_1$b.sidi[index_1],
    s.sidi = dat_1$s.sidi[index_2]
  )

fit_resampled_i = lm(b.sidi ~ s.sidi, data = dat_resampled_i)
slope_resampled_i = coef(fit_resampled_i)[2]

print(slope_resampled_i)

plot(
  b.sidi ~ s.sidi, data = dat_resampled_i,
  main = "Simpson's diversity indices (MC resampled data)",
  xlab = "Vegetation cover diversity",
  ylab = "Bird diversity")
abline(fit_resampled_i)
```

**Q15: In your report, include a plot of your histogram of Monte Carlo resampled slopes. Include vertical lines showing the observed slope and the critical value from the resampled MC slopes.**

```{r}
#Monte Carlo Randomization Loop
dat_1 = 
  subset(
    dat_all,
    select = c(b.sidi, s.sidi))

dat_1
m = 10000 
result_mc = numeric(m) 

for(i in 1:m)
{
  index_1 = sample(nrow(dat_1), replace = TRUE)
  index_2 = sample(nrow(dat_1), replace = TRUE)
  
  dat_resampled_i = 
  data.frame(
    b.sidi = dat_1$b.sidi[index_1],
    s.sidi = dat_1$s.sidi[index_2]
    )
  
fit_resampled_i = lm(b.sidi ~ s.sidi, data = dat_resampled_i)
  
  result_mc[i] = coef(fit_resampled_i)[2]
} 

fit_2 = lm(b.sidi ~ s.sidi, data = dat_1)
coef(fit_2)
slope_observed = coef(fit_2)[2]
crit_v <- quantile(result_mc, c(.05))

hist(result_mc,
  main = "Ednita's Null Distribution of Regression Slope",
  xlab = "Slope Parameter", col = "pink")
abline(v = slope_observed, lty = 2, col = "blue", lwd = 2)
abline(v = crit_v, lty = 2, col = "black", lwd = 2
)
```

**Q16: What was your critical value? Was the observed slope less than the critical value?**

The critical value was -.013, the observed slope was -.024 which means that the observed sloe is greater than the critical value.

```{r}
quantile(result_mc, c(.05))
```

**Q17: What is your conclusion regarding the evidence of a negative relationship between vegetation cover diversity and bird diversity? Make sure to justify your conclusions using the results of your simulation analysis.**

It shows that there is no significant difference between the vegetation cover density and the bird diversity. 

## Bootstraping
```{r}
dat_1 = 
  subset(
    dat_all,
    select = c(b.sidi, s.sidi))

set.seed(345)
index_1 = sample(nrow(dat_1), replace = TRUE)
dat_boot = dat_1[index_1, ]
head(dat_boot)

fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)
coef(fit_bs1)

result_boot = coef(fit_bs1)

m = 10000 
result_boot = numeric(m) 

for(i in 1:m)
  
{
  index_1 = sample(nrow(dat_1), replace = TRUE)
  
  dat_boot = dat_1[index_1, ]
  
  fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)
  
  head(dat_boot)
  coef(fit_bs1)
  
  result_boot[i] = coef(fit_bs1)[2]
} 


fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_1)
coef(fit_bs1)
slope_observed = coef(fit_bs1)[2]
crit_v <- quantile(result_boot, c(.05))

hist(
  result_boot,
  main = "Ednita's Alternative Distribution of Regression Slope",
  xlab = "Slope Parameter", col = "pink")
abline(v = slope_observed, lty = 2, col = "blue", lwd = 2)
abline(v = 0, lty = 2, col = 1, lwd = 2)

plot(density(result_mc), col= "black", xlab = "Slope Coefficient")

plot(density(result_boot), main = "Ednita's Double Density Plot", xlab = "Slope Coefficient", ylab= "Density", col= "blue")

lines(density(result_mc))

legend(-.05, 50, legend=c("Monte Carlo", "Bootstrap"),fill = c("black","blue"))

```

**Q18: Show the code you used in your bootstrap loop**

```{r}
m = 10000 
result_boot = numeric(m) 

for(i in 1:m)
  
{
  index_1 = sample(nrow(dat_1), replace = TRUE)
  
  dat_boot = dat_1[index_1, ]
  
  fit_bs1 = lm(b.sidi ~ s.sidi, data = dat_boot)
  
  head(dat_boot)
  coef(fit_bs1)
  
  result_boot[i] = coef(fit_bs1)[2]
} 

```

**Q19: Include your double density plot. For full credit your plot must include:
a legend
the two density curves, in different colors
appropriate axis labels and title

```{r}
plot(density(result_mc), col= "black", xlab = "Slope Coefficient")

plot(density(result_boot), main = "Ednita's Double Density Plot", xlab = "Slope Coefficient", ylab= "Density", col= "blue")

lines(density(result_mc))

legend(-.05, 50, legend=c("Monte Carlo", "Bootstrap"), fill = c("black","blue"))

```

**Q20: Recall that the bootstrap curve shows the distribution of plausible values for the slope coefficient if we could resample the original data. The Monte Carlo curve shows the distribution of plausible values for the slope coefficient if the null hypothesis were true. How can you interpret the region that falls under both curves?**

I would interpret the region that falls under both curves as not useful because it would both accept and reject the null hypothesis.  

